use crate::controller::vec_string_to_vec_platform;
use crate::error::{Error, Result};
use crate::graph::edge::{HoldRecord, IdentityFromToRecord};
use crate::graph::vertex::{Identity, IdentityRecord, IdentityWithSource, Vertex};
use crate::graph::ConnectionPool;
use crate::tigergraph::edge::{
    EdgeRecord, EdgeUnion, FromWithParams, Hold, HoldRecord as HoldRecord2, Proof,
    ProofRecord as ProofRecord2,
};
use crate::upstream::DataFetcher;
use crate::upstream::{fetch_all, ContractCategory, DataSource, Platform, Target};
use async_graphql::{Context, Object, ObjectType, Union};
use deadpool::managed::Object;
use strum::IntoEnumIterator;
use tracing::{debug, event, Level};
use uuid::Uuid;

/// Status for a record in RelationService DB
#[derive(Default, Copy, Clone, PartialEq, Eq, async_graphql::Enum)]
enum DataStatus {
    /// Fetched or not in Database.
    #[default]
    #[graphql(name = "cached")]
    Cached,

    /// Outdated record
    #[graphql(name = "outdated")]
    Outdated,

    /// Fetching this data.
    /// The result you got maybe outdated.
    /// Come back later if you want a fresh one.
    #[graphql(name = "fetching")]
    Fetching,
}

#[Object]
impl ProofRecord2 {
    async fn e_type(&self) -> &str {
        &self.e_type
    }

    async fn directed(&self) -> bool {
        self.directed
    }

    async fn from_id(&self) -> &str {
        &self.from_id
    }

    async fn from_type(&self) -> &str {
        &self.from_type
    }

    async fn to_id(&self) -> &str {
        &self.to_id
    }

    async fn to_type(&self) -> &str {
        &self.to_type
    }

    /// UUID of this record. Generated by us to provide a better
    /// global-uniqueness for future P2P-network data exchange
    /// scenario.
    async fn uuid(&self) -> String {
        self.attributes.uuid.to_string()
    }

    /// Data source (upstream) which provides this connection info.
    async fn source(&self) -> String {
        self.attributes.source.to_string()
    }

    /// Level which provides this connection confidence level.
    async fn level(&self) -> String {
        self.attributes.level.to_string()
    }

    /// ID of this connection in upstream platform to locate (if any).
    async fn record_id(&self) -> Option<String> {
        self.attributes.record_id.clone()
    }

    /// When this connection is recorded in upstream platform (if platform gives such data).
    async fn created_at(&self) -> Option<i64> {
        self.attributes.created_at.map(|ca| ca.timestamp())
    }

    /// When this connection is fetched by us RelationService.
    async fn updated_at(&self) -> i64 {
        self.attributes.updated_at.timestamp()
    }

    /// Who collects this data.
    /// It works as a "data cleansing" or "proxy" between `source`s and us.
    async fn fetcher(&self) -> DataFetcher {
        self.attributes.fetcher
    }
}

#[Object]
impl HoldRecord2 {
    async fn e_type(&self) -> &str {
        &self.e_type
    }

    async fn directed(&self) -> bool {
        self.directed
    }

    async fn from_id(&self) -> &str {
        &self.from_id
    }

    async fn from_type(&self) -> &str {
        &self.from_type
    }

    async fn to_id(&self) -> &str {
        &self.to_id
    }

    async fn to_type(&self) -> &str {
        &self.to_type
    }

    /// UUID of this record.
    async fn uuid(&self) -> Uuid {
        self.attributes.uuid
    }

    /// Data source (upstream) which provides this info.
    /// Theoretically, Contract info should only be fetched by chain's RPC server,
    /// but in practice, we still rely on third-party cache / snapshot service.
    async fn source(&self) -> DataSource {
        self.attributes.source
    }

    /// Transaction info of this connection.
    /// i.e. in which `tx` the Contract is transferred / minted.
    /// In most case, it is a `"0xVERY_LONG_HEXSTRING"`.
    /// It happens that this info is not provided by `source`, so we treat it as `Option<>`.
    async fn transaction(&self) -> Option<String> {
        self.attributes.transaction.clone()
    }

    /// NFT_ID in contract / ENS domain / anything can be used as an unique ID to specify the held object.
    /// It must be one here.
    /// Tips: NFT_ID of ENS is a hash of domain. So domain can be used as NFT_ID.
    async fn id(&self) -> String {
        self.attributes.id.clone()
    }

    /// When the transaction happened. May not be provided by upstream.
    async fn created_at(&self) -> Option<i64> {
        self.attributes.created_at.map(|dt| dt.timestamp())
    }

    /// When this HODLâ„¢ relation is fetched by us RelationService.
    async fn updated_at(&self) -> i64 {
        self.attributes.updated_at.timestamp()
    }

    /// Who collects this data.
    /// It works as a "data cleansing" or "proxy" between `source`s and us.
    async fn fetcher(&self) -> DataFetcher {
        self.attributes.fetcher
    }
}

#[Object]
impl IdentityWithSource {
    async fn sources(&self) -> Vec<DataSource> {
        self.sources.clone()
    }

    async fn identity(&self) -> IdentityRecord {
        self.identity.clone()
    }
}

#[Object]
impl IdentityRecord {
    /// Status for this record in RelationService.
    async fn status(&self) -> Vec<DataStatus> {
        use DataStatus::*;
        let mut current: Vec<DataStatus> = vec![];
        if !self.key().is_empty() {
            current.push(Cached);
            if self.is_outdated() {
                current.push(Outdated);
            }
        } else {
            current.push(Fetching); // FIXME: Seems like this is never reached.
        }
        current
    }

    async fn records(&self) -> Vec<EdgeUnion> {
        vec![
            EdgeUnion::ProofRecord(ProofRecord2(EdgeRecord::from_with_params(
                "name".to_string(),
                true,
                "from.primary_key()".to_string(),
                "from.vertex_type()".to_string(),
                "to.primary_key()".to_string(),
                "to.vertex_type()".to_string(),
                Proof::default(),
            ))),
            EdgeUnion::HoldRecord(HoldRecord2(EdgeRecord::from_with_params(
                "name".to_string(),
                true,
                "from.primary_key()".to_string(),
                "from.vertex_type()".to_string(),
                "to.primary_key()".to_string(),
                "to.vertex_type()".to_string(),
                Hold::default(),
            ))),
        ]
    }

    /// UUID of this record.  Generated by us to provide a better
    /// global-uniqueness for future P2P-network data exchange
    /// scenario.
    async fn uuid(&self) -> Option<String> {
        self.uuid.map(|u| u.to_string())
    }

    /// Platform.  See `avaliablePlatforms` or schema definition for a
    /// list of platforms supported by RelationService.
    async fn platform(&self) -> Platform {
        self.platform
    }

    /// Identity on target platform.  Username or database primary key
    /// (prefer, usually digits).  e.g. `Twitter` has this digits-like
    /// user ID thing.
    async fn identity(&self) -> String {
        self.identity.clone()
    }

    /// Usually user-friendly screen name.  e.g. for `Twitter`, this
    /// is the user's `screen_name`.
    /// Note: both `null` and `""` should be treated as "no value".
    async fn display_name(&self) -> Option<String> {
        self.display_name.clone()
    }

    /// URL to target identity profile page on `platform` (if any).
    async fn profile_url(&self) -> Option<String> {
        self.profile_url.clone()
    }

    /// URL to avatar (if any is recorded and given by target platform).
    async fn avatar_url(&self) -> Option<String> {
        self.avatar_url.clone()
    }

    /// Account / identity creation time ON TARGET PLATFORM.
    /// This is not necessarily the same as the creation time of the record in the database.
    /// Since `created_at` may not be recorded or given by target platform.
    /// e.g. `Twitter` has a `created_at` in the user profile API.
    /// but `Ethereum` is obviously no such thing.
    async fn created_at(&self) -> Option<i64> {
        self.created_at.map(|dt| dt.timestamp())
    }

    /// When this Identity is added into this database.
    /// Second-based unix timestamp.
    /// Generated by us.
    async fn added_at(&self) -> i64 {
        self.added_at.timestamp()
    }

    /// When it is updated (re-fetched) by us RelationService.
    /// Second-based unix timestamp.
    /// Managed by us.
    async fn updated_at(&self) -> i64 {
        self.updated_at.timestamp()
    }

    /// Neighbor identity from current. Flattened.
    // FIXME: <2023-04-23 SUN> broken of high CPU / bandwidth consumption. Maybe something is wrong with SQL.
    async fn neighbor(
        &self,
        ctx: &Context<'_>,
        // #[graphql(
        //     desc = "Upstream source of this connection. Will search all upstreams if omitted."
        // )]
        // upstream: Option<String>,
        #[graphql(desc = "Depth of traversal. 1 if omitted")] depth: Option<u16>,
    ) -> Result<Vec<IdentityWithSource>> {
        let pool: &ConnectionPool = ctx.data().map_err(|err| Error::PoolError(err.message))?;
        debug!("Connection pool status: {:?}", pool.status());

        self.neighbors(
            pool,
            depth.unwrap_or(1),
            // upstream.map(|u| DataSource::from_str(&u).unwrap_or(DataSource::Unknown))
            None,
        )
        .await
    }

    async fn neighbor_with_traversal(
        &self,
        ctx: &Context<'_>,
        #[graphql(desc = "Depth of traversal. 1 if omitted")] depth: Option<u16>,
    ) -> Result<Vec<IdentityFromToRecord>> {
        let pool: &ConnectionPool = ctx.data().map_err(|err| Error::PoolError(err.message))?;
        debug!("Connection pool status: {:?}", pool.status());
        self.neighbors_with_traversal(pool, depth.unwrap_or(1))
            .await
    }

    /// there's only `platform: lens` identity `ownedBy` is not null
    async fn owned_by(&self, ctx: &Context<'_>) -> Result<Option<IdentityRecord>> {
        if vec![
            Platform::Lens,
            Platform::Dotbit,
            Platform::UnstoppableDomains,
        ]
        .contains(&self.platform)
        {
            return Ok(None);
        }
        let pool: &ConnectionPool = ctx.data().map_err(|err| Error::PoolError(err.message))?;
        debug!("Connection pool status: {:?}", pool.status());
        self.domain_owned_by(pool).await
    }

    /// NFTs owned by this identity.
    /// For now, there's only `platform: ethereum` identity has NFTs.
    /// If `category` is provided, only NFTs of that category will be returned.
    async fn nft(
        &self,
        ctx: &Context<'_>,
        #[graphql(
            desc = "Filter condition for ContractCategory. If not provided or empty array, all category NFTs will be returned."
        )]
        category: Option<Vec<ContractCategory>>,
    ) -> Result<Vec<HoldRecord>> {
        let pool: &ConnectionPool = ctx.data().map_err(|err| Error::PoolError(err.message))?;
        debug!("Connection pool status: {:?}", pool.status());
        self.nfts(pool, category).await
    }
}

#[derive(Default)]
pub struct IdentityQuery;

#[Object]
impl IdentityQuery {
    /// Returns a list of all platforms supported by RelationService.
    async fn available_platforms(&self) -> Result<Vec<Platform>> {
        Ok(Platform::iter().collect())
    }

    /// Returns a list of all upstreams (data sources) supported by RelationService.
    async fn available_upstreams(&self) -> Result<Vec<DataSource>> {
        Ok(DataSource::iter().collect())
    }

    /// Query an `identity` by given `platform` and `identity`.
    #[tracing::instrument(level = "trace", skip(self, ctx))]
    async fn identity(
        &self,
        ctx: &Context<'_>,
        #[graphql(desc = "Platform to query")] platform: String,
        #[graphql(desc = "Identity on target Platform")] identity: String,
    ) -> Result<Option<IdentityRecord>> {
        // let db: &DatabaseConnection = ctx.data().map_err(|err| Error::GraphQLError(err.message))?;
        let pool: &ConnectionPool = ctx.data().map_err(|err| Error::PoolError(err.message))?;
        debug!("Connection pool status: {:?}", pool.status());

        let conn = pool
            .get()
            .await
            .map_err(|err| Error::PoolError(err.to_string()))?;
        let db = Object::take(conn);

        let platform: Platform = platform.parse()?;
        let target = Target::Identity(platform, identity.clone());
        // FIXME: Still kinda dirty. Should be in an background queue/worker-like shape.
        match Identity::find_by_platform_identity(&db, &platform, &identity).await? {
            None => {
                let fetch_result = fetch_all(target).await;
                if fetch_result.is_err() {
                    event!(
                        Level::WARN,
                        ?platform,
                        identity,
                        err = fetch_result.unwrap_err().to_string(),
                        "Failed to fetch"
                    );
                }
                Ok(Identity::find_by_platform_identity(&db, &platform, &identity).await?)
            }
            Some(found) => {
                if found.is_outdated() {
                    event!(Level::DEBUG, ?platform, identity, "Outdated. Refetching.");
                    tokio::spawn(fetch_all(target)); // Fetch in the background
                }
                Ok(Some(found))
            }
        }
    }

    async fn identities(
        &self,
        ctx: &Context<'_>,
        #[graphql(desc = "Platform array to query")] platforms: Vec<String>,
        #[graphql(desc = "Identity on target Platform")] identity: String,
    ) -> Result<Vec<IdentityRecord>> {
        let pool: &ConnectionPool = ctx.data().map_err(|err| Error::GraphQLError(err.message))?;
        debug!("Connection pool status: {:?}", pool.status());

        let platform_list = vec_string_to_vec_platform(platforms)?;
        let record: Vec<IdentityRecord> =
            Identity::find_by_platforms_identity(&pool, &platform_list, identity.as_str()).await?;
        if record.len() == 0 {
            for platform in &platform_list {
                let target = Target::Identity(platform.clone(), identity.clone());
                let _ = fetch_all(target).await;
            }
            Identity::find_by_platforms_identity(&pool, &platform_list, identity.as_str()).await
        } else {
            record.iter().filter(|r| r.is_outdated()).for_each(|r| {
                // Refetch in the background
                tokio::spawn(fetch_all(Target::Identity(
                    r.platform.clone(),
                    r.identity.clone(),
                )));
            });
            Ok(record)
        }
    }
}
